{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF embedding\n",
    "TF-IDF (term frequency-inverse document frequency) embedding is a technique used to represent text documents as numerical vectors. It is commonly used for natural language processing tasks such as text classification, information retrieval and text similarity comparison. The idea behind TF-IDF is to give more weight to words that are more informative and less common within a given corpus of documents.\n",
    "The TF-IDF score of a word is calculated as the product of its term frequency (TF) and inverse document frequency (IDF). The TF is the number of times a word appears in a document, while the IDF is the logarithm of the ratio of the total number of documents to the number of documents containing the word. Words that appear frequently in many documents will have a lower IDF score and therefore, lower overall TF-IDF score, while words that appear infrequently in a few documents will have a higher IDF score and therefore, higher overall TF-IDF score.\n",
    "TF-IDF embedding is useful for text classification, as it allows models to understand the importance of different words in a document and classify the text based on these features. It can also be used for information retrieval, by finding the documents most relevant to a query by comparing their tf-idf vectors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "citation: https://github.com/omkar34/products-recommendation/blob/master/product_recommend.ipynb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libirares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import portion of a package\n",
    "import matplotlib.pyplot as plt  # Most common visualization package that a lot of others are based on\n",
    "\n",
    "# Import full packages under custom name\n",
    "import numpy as np  # Common package for numerical methods\n",
    "import pandas as pd  # Common package for data storeage/manipulation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get product detail data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_detail_detail_path = \"./clean_data/cleaned_products_detailed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_standard = pd.read_csv(product_detail_detail_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_standard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get product description, and filter wrong data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed = df_product_standard[['ctr_product_num','attr_value_en_sentence']]\n",
    "df_detailed = df_detailed.dropna()\n",
    "df_detailed = df_detailed.drop_duplicates()\n",
    "df_detailed = df_detailed[~df_detailed.attr_value_en_sentence.isin(['Features and Benefits not loaded','NaN','Features and benefits not loaded','Features and Benefits not loaded','Features and Benefits not loaded,'])]\n",
    "df_detailed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tfidf vectorizer, containing trigram and bigram which is 2 words and 3 words combination, filter words occur less than 1000 times, remove stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting tfidf vectorizer\n",
    "tf = TfidfVectorizer(ngram_range =(1,3), min_df=1000, stop_words = 'english',analyzer='word')\n",
    "tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf matrix\n",
    "tf_matrix = tf.fit_transform(df_detailed['attr_value_en_sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame(tf_matrix.toarray(),columns = tf.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the tfidf vectorizer with row equal to product, column equal to unique words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = tf_df.join(df_detailed['ctr_product_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.set_index('ctr_product_num', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.to_csv(\"embeddings/TFIDF_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "553e32e48ac880454f5cffdbdb5a760352d718aa046ed296baeaf7bc461bea05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
