{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Tokenize the data and add it to the data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_detail_path = \"clean_data/cleaned_products_detailed.csv\"\n",
    "df_product_detailed = pd.read_csv(product_detail_path)\n",
    "df_detailed = df_product_detailed[['ctr_product_num','attr_value_en_sentence']]\n",
    "df_detailed = df_detailed.dropna()\n",
    "df_detailed = df_detailed.drop_duplicates()\n",
    "df_detailed_subset = df_detailed.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235418, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detailed_subset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the input data is a list of vocabulary corresponding to each \"ctr_product_num\". each word will gain a vector representation after word2vec, and in order to convert to doc2vec, we average the vector value for all words in that product description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.1', 'cm', 'maximum', 'detection', 'depth', 'Center', 'and', 'Edge', 'Finder', 'LEDs', 'track', 'the', 'center', 'and', 'edges', 'of', 'studs', 'simultaneously', 'Finds', 'wood', 'and', 'metal', 'studs', 'Deep-scan', 'mode', 'is', 'always', 'on', 'ACCURATE,', 'The', 'multiple', 'LEDs', 'track', 'the', 'location', 'of', 'studs', 'to', 'accurately', 'and', 'reliably', 'identify', 'the', 'center', 'and', 'edges', 'of', 'studs', 'simultaneously', 'EASY,', 'Just', 'press', 'and', 'hold', 'te', 'botton', 'to', 'instantly', 'detect', 'studs.', 'No', 'calibraiton', 'required.', 'HOW', 'IT', 'WORKS,', 'The', 'ProSensor', 'T11', 'has', '11', 'sensors', 'and', 'has', 'Multi-Sense', 'Technology.', 'In', 'comparison,', 'conventional', 'stud', 'finders', 'have', '1', 'or', '2', 'sensors.', 'With', 'more', 'sensors,', 'the', 'T11', 'more', 'accurately', 'identifies', 'the', 'location', 'of', 'studs']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctr_product_num</th>\n",
       "      <th>attr_value_en_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210785</th>\n",
       "      <td>574627</td>\n",
       "      <td>4.1 cm maximum detection depth\\nCenter and Edg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215023</th>\n",
       "      <td>8423863</td>\n",
       "      <td>Turn into an old geezer this Halloween with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193812</th>\n",
       "      <td>8421970</td>\n",
       "      <td>Fill the room with shine and color for a loved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328004</th>\n",
       "      <td>766404</td>\n",
       "      <td>Perfect heated solution for all your camp/outd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136326</th>\n",
       "      <td>482267</td>\n",
       "      <td>Peelable rubber coating that enables endless c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ctr_product_num                             attr_value_en_sentence\n",
       "210785            574627  4.1 cm maximum detection depth\\nCenter and Edg...\n",
       "1215023          8423863  Turn into an old geezer this Halloween with a ...\n",
       "1193812          8421970  Fill the room with shine and color for a loved...\n",
       "328004            766404  Perfect heated solution for all your camp/outd...\n",
       "136326            482267  Peelable rubber coating that enables endless c..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for i, row in df_detailed_subset.iterrows():\n",
    "    data.append(row['attr_value_en_sentence'].split())\n",
    "\n",
    "print(data[0])\n",
    "df_detailed_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = Word2Vec(data, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to generate product embeddings\n",
    "product_embeddings = {}\n",
    "for i, row in df_detailed_subset.iterrows():\n",
    "    # Generate an embedding for the entire product sentence by concatenating the individual word embeddings\n",
    "    product_embedding = np.mean([model.wv[word] for word in row['attr_value_en_sentence'].split()], axis=0)\n",
    "    product_embeddings[row['ctr_product_num']] = product_embedding\n",
    "\n",
    "embeddings_dict = pd.DataFrame.from_dict(product_embeddings, orient='index')\n",
    "embeddings_dict.index.names = [\"ctr_product_num\"]\n",
    "\n",
    "embeddings_dict.to_csv(\"embeddings/prod2vec_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Extract the product embeddings from the product_embeddings dictionary\n",
    "product_embeddings_list = np.array(list(product_embeddings.values()))\n",
    "\n",
    "# Use t-SNE to reduce the dimensions of the product embeddings\n",
    "tsne = TSNE(n_components=3)\n",
    "product_embeddings_3d = tsne.fit_transform(product_embeddings_list)\n",
    "\n",
    "# Extract the product names from the product_embeddings dictionary\n",
    "product_names = list(product_embeddings.keys())\n",
    "\n",
    "# Create a dataframe with the product embeddings and names\n",
    "df = pd.DataFrame({'x': product_embeddings_3d[:, 0], 'y': product_embeddings_3d[:, 1], 'z': product_embeddings_3d[:, 2], 'product': product_names})\n",
    "\n",
    "# Plot the product embeddings in 3D using plotly\n",
    "fig = px.scatter_3d(df, x='x', y='y', z='z', text='product')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_standard = \"Data\\product\\product_standard_attributes.csv\" \n",
    "\n",
    "# put it in data farme\n",
    "df_product_standard = pd.read_csv(path_standard, low_memory=False) #lazyway to solve low memory issue\n",
    "df_right =df_product_standard[['ctr_product_num','short_desc']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_right['ctr_product_num'] = pd.to_numeric(df_right['ctr_product_num'], errors='coerce')\n",
    "df_right = df_right.dropna(subset=['ctr_product_num'])\n",
    "df_right['ctr_product_num'] = df_right['ctr_product_num'].astype('int')\n",
    "df_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df_detailed_subset.merge(df_right, on='ctr_product_num', how='left')\n",
    "df_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_desc.iterrows():\n",
    "    # Generate an embedding for the entire product sentence by concatenating the individual word embeddings\n",
    "    product_embedding = np.mean([model.wv[word] for word in row['attr_value_en_sentence'].split()], axis=0)\n",
    "    product_embeddings[row['ctr_product_num']] = product_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Labels separately on a line-by-line manner.\n",
    "with open('visualization/metadata.tsv', \"w\") as f:\n",
    "  for i, row in df_desc.iterrows():\n",
    "    f.write(\"{}\\n\".format(row['short_desc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tfflow\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins import projector\n",
    "# Extract the product embeddings from the product_embeddings dictionary\n",
    "product_embeddings_list = list(product_embeddings.values())\n",
    "\n",
    "# Convert the product embeddings to a numpy array\n",
    "product_embeddings_array = np.array(product_embeddings_list, dtype=np.float32)\n",
    "\n",
    "# Use t-SNE to reduce the dimensions of the product embeddings\n",
    "tsne = TSNE(perplexity=30,n_components=3)\n",
    "product_embeddings_3d = tsne.fit_transform(product_embeddings_array)\n",
    "#print(product_embeddings_array)\n",
    "#print(product_embeddings_3d)\n",
    "# Save the dataset to a file\n",
    "with open('visualization/product_embeddings_3d.tsv', 'w') as f:\n",
    "    for x, y, z in product_embeddings_3d:\n",
    "        f.write(f\"{x}\\t{y}\\t{z}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "713c6a8077557bf6b12f32534318771ae7cac7046ada6a98be74843782a407b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
