{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline One-Hot Evaluation Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the baseline results of various evaluation models with the one-hot encoded product data, and a confusion matrix. It shows the preliminary process of testing out different regression models and neural networks. The team selected an MLP Classifier as the main evaluation model to use going forward. Please see Evaluation.ipynb for the full evaluation process of the team's embeddings.\n",
    "\n",
    "The classification task is to predict \"merch_lob_nm\". The onehot encoded vectors exclude any heirarchical data (merch_division_nm, merch_lob_nm, merch_bus_cat_nm, merch_subcat_nm, merch_fineline_nm) for a fair prediction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references: \n",
    "\n",
    "https://www.statology.org/one-hot-encoding-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages for this lab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Import linear regression models\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "\n",
    "# Import logistic regression models\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "# Import confusion matrix function from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_onehot_path = \"embeddings\\onehot.csv\"\n",
    "df_cont_and_onehot = pd.read_csv(product_onehot_path, index_col=0, header=0)\n",
    "\n",
    "store_onehot_path = \"embeddings\\onehot_store.csv\"\n",
    "df_cont_and_onehot_store = pd.read_csv(store_onehot_path, index_col=0, header=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product One-hot Embedding Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_path = \"clean_data/cleaned_products.csv\"\n",
    "df_product_standard = pd.read_csv(product_path)\n",
    "df_product_standard = df_product_standard[[\"ctr_product_num\", \"merch_lob_nm\"]]\n",
    "\n",
    "df_cont_and_onehot = df_cont_and_onehot.join(df_product_standard.set_index(\"ctr_product_num\"))\n",
    "df_cont_and_onehot.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_and_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace merch_lob_nm with numerical values\n",
    "#original_label = df_cont_and_onehot.merch_lob_nm\n",
    "#df_cont_and_onehot.merch_lob_nm = pd.Categorical(pd.factorize(df_cont_and_onehot.merch_lob_nm)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mapping of original label to the new numerical label\n",
    "#label_map = dict(zip(df_cont_and_onehot['merch_lob_nm'], original_label))\n",
    "#label_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 100k products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont_and_onehot100k = df_cont_and_onehot.sample(frac=1, random_state=42)[:100000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train test split for product embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_for_X = [\"merch_lob_nm\"]\n",
    "\n",
    "X = df_cont_and_onehot100k.drop(columns=drop_for_X)\n",
    "Y = df_cont_and_onehot100k[[\"merch_lob_nm\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier (Neural Network Model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 hidden layers\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(150, 100, 50), random_state=1, max_iter=300).fit(X_train, y_train)\n",
    "\n",
    "train_score = mlp.score(X_train, y_train)\n",
    "test_score = mlp.score(X_test, y_test)\n",
    "\n",
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store One-hot Embedding Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the sales data\n",
    "store_sales_path = \"embeddings\\store_embeddings\\store_sales_embedding.csv\"\n",
    "df_sales = pd.read_csv(store_sales_path)\n",
    "df_sales = df_sales[[\"yr_num\",\"wk_num\",\"store_num\",\"sales_qty\"]]\n",
    "\n",
    "#append one-hot store embeddings onto the sales data \n",
    "df_cont_and_onehot_store = df_cont_and_onehot_store.join(df_sales.set_index(\"store_num\"))\n",
    "df_cont_and_onehot_store.dropna(inplace=True)\n",
    "df_cont_and_onehot_store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Forecasting using Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "\n",
    "#shuffle the data\n",
    "df = df_cont_and_onehot_store.sample(frac=1, random_state=42)\n",
    "\n",
    "drop_for_X = [\"sales_qty\"]\n",
    "\n",
    "X = df.drop(columns=drop_for_X)\n",
    "Y = df[[\"sales_qty\"]]\n",
    "\n",
    "#obtain train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Lasso CV applies cross validation automatically\n",
    "linreg = LassoCV()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sales\n",
    "y_test_predictions = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "train_score = linreg.score(X_train, y_train)\n",
    "test_score = linreg.score(X_test, y_test)\n",
    "print(f'The train score is {train_score:.3f} and the test score is {test_score:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline R^2 score for the Store Entity Embeddings is 0.509 on the test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctciter1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ba15d0a7ddc87a7cdc03ddbf3292318d97fc3790c5fcb6de245b479ad7e98a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
